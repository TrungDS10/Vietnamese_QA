{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_ChA8ONwbsg"
      },
      "source": [
        "## Introduction to Question Answering\n",
        "\n",
        "Question answering is a common NLP task with several variants. In some variants, the task\n",
        "is multiple-choice:\n",
        "A list of possible answers are supplied with each question, and the model simply needs to\n",
        "return a probability distribution over the options. A more challenging variant of\n",
        "question answering, which is more applicable to real-life tasks, is when the options are\n",
        "not provided. Instead, the model is given an input document -- called context -- and a\n",
        "question about the document, and it must extract the span of text in the document that\n",
        "contains the answer. In this case, the model is not computing a probability distribution\n",
        "over answers, but two probability distributions over the tokens in the document text,\n",
        "representing the start and end of the span containing the answer. This variant is called\n",
        "\"extractive question answering\".\n",
        "\n",
        "Extractive question answering is a very challenging NLP task, and the dataset size\n",
        "required to train such a model from scratch when the questions and answers are natural\n",
        "language is prohibitively huge. As a result, question answering (like almost all NLP\n",
        "tasks) benefits enormously from starting from a strong pretrained foundation model -\n",
        "starting from a strong pretrained language model can reduce the dataset size required to\n",
        "reach a given accuracy by multiple orders of magnitude, enabling you to reach very strong\n",
        "performance with surprisingly reasonable datasets.\n",
        "\n",
        "Starting with a pretrained model adds difficulties, though - where do you get the model\n",
        "from? How do you ensure that your input data is preprocessed and tokenized the same way\n",
        "as the original model? How do you modify the model to add an output head that matches\n",
        "your task of interest?\n",
        "\n",
        "In this example, we'll show you how to load a model from the Hugging Face\n",
        "[ðŸ¤—Transformers](https://github.com/huggingface/transformers) library to tackle this\n",
        "challenge. We'll also load a benchmark question answering dataset from the\n",
        "[ðŸ¤—Datasets](https://github.com/huggingface/datasets) library - this is another open-source\n",
        "repository containing a wide range of datasets across many modalities, from NLP to vision\n",
        "and beyond. Note, though, that there is no requirement that these libraries must be used\n",
        "with each other. If you want to train a model from\n",
        "[ðŸ¤—Transformers](https://github.com/huggingface/transformers) on your own data, or you want\n",
        "to load data from [ðŸ¤— Datasets](https://github.com/huggingface/datasets) and train your\n",
        "own entirely unrelated models with it, that is of course possible (and highly\n",
        "encouraged!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTgeDJlQwbsh"
      },
      "source": [
        "##Â Installing the requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "muOeOIslwbsh",
        "outputId": "e7dac092-8a74-47cc-c6ea-320361859e67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-6u7m4eug\n",
            "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-6u7m4eug\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (3.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.26.0.dev0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.26.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (0.11.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub) (3.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub) (6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install datasets\n",
        "!pip install huggingface-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSUoqcbswbsi"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF_JqVLiwbsj"
      },
      "source": [
        "We will use the [ðŸ¤— Datasets](https://github.com/huggingface/datasets) library to download\n",
        "the UIT-Vi question answering dataset using `load_dataset()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DgUF2pwxwbsj",
        "outputId": "20e9d239-0e62-4a14-b4b2-ffb7a4a8b1bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "ac94f895defc48a589dca8bf03f12b40",
            "b0ea51a113b146c390edc2127ee15b16",
            "25fe697708cf45fdbfcd54c0a987beeb",
            "ed0c24e76ab546119559eea0545914b6",
            "bb27c1d8b4754fc5b9bb8cd54499f87b",
            "2aa4e7b2bdd3436fb67cdc8be5f4c61c",
            "a89354e3aca0448389bbafba72b7c96e",
            "8bf4d906d4504139b1d151838ae711d9",
            "80928868adcb4686a73930be5af4151a",
            "36d53e5d6f9f44d8aff410eb5ecc57f0",
            "bdc47afcbc3045b784e74631b1d1f298"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset uit-vi-squad (/root/.cache/huggingface/datasets/trungds10___uit-vi-squad/squad_v2/2.0.0/5f19aa36ebeb9b5dc65031d4651dbedf62262d7034d4d2b9cca43a6694a23cb7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac94f895defc48a589dca8bf03f12b40"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "datasets = load_dataset(\"trungds10/UIT-Vi-Squad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y0n38JKwbsj"
      },
      "source": [
        "The `datasets` object itself is a\n",
        "`DatasetDict`, which contains one key for the training, validation and test set. We can see\n",
        "the training, validation and test sets all have a column for the context, the question\n",
        "and the answers to those questions. To access an actual element, you need to select a\n",
        "split first, then give an index. We can see the answers are indicated by their start\n",
        "position in the text and their full text, which is a substring of the context as we\n",
        "mentioned above. Let's take a look at what a single training example looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HePbKnwewbsk",
        "outputId": "f079181b-28ee-433b-f77e-ec70626a1bac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'uit_000001', 'title': 'Pháº¡m VÄƒn Äá»“ng', 'context': 'Pháº¡m VÄƒn Äá»“ng (1 thÃ¡ng 3 nÄƒm 1906 â€“ 29 thÃ¡ng 4 nÄƒm 2000) lÃ  Thá»§ tÆ°á»›ng Ä‘áº§u tiÃªn cá»§a nÆ°á»›c Cá»™ng hÃ²a XÃ£ há»™i chá»§ nghÄ©a Viá»‡t Nam tá»« nÄƒm 1976 (tá»« nÄƒm 1981 gá»i lÃ  Chá»§ tá»‹ch Há»™i Ä‘á»“ng Bá»™ trÆ°á»Ÿng) cho Ä‘áº¿n khi nghá»‰ hÆ°u nÄƒm 1987. TrÆ°á»›c Ä‘Ã³ Ã´ng tá»«ng giá»¯ chá»©c vá»¥ Thá»§ tÆ°á»›ng ChÃ­nh phá»§ Viá»‡t Nam DÃ¢n chá»§ Cá»™ng hÃ²a tá»« nÄƒm 1955 Ä‘áº¿n nÄƒm 1976. Ã”ng lÃ  vá»‹ Thá»§ tÆ°á»›ng Viá»‡t Nam táº¡i vá»‹ lÃ¢u nháº¥t (1955â€“1987). Ã”ng lÃ  há»c trÃ², cá»™ng sá»± cá»§a Chá»§ tá»‹ch Há»“ ChÃ­ Minh. Ã”ng cÃ³ tÃªn gá»i thÃ¢n máº­t lÃ  TÃ´, Ä‘Ã¢y tá»«ng lÃ  bÃ­ danh cá»§a Ã´ng. Ã”ng cÃ²n cÃ³ tÃªn gá»i lÃ  LÃ¢m BÃ¡ Kiá»‡t khi lÃ m PhÃ³ chá»§ nhiá»‡m cÆ¡ quan Biá»‡n sá»± xá»© táº¡i Quáº¿ LÃ¢m (Chá»§ nhiá»‡m lÃ  Há»“ Há»c LÃ£m).', 'question': 'TÃªn gá»i nÃ o Ä‘Æ°á»£c Pháº¡m VÄƒn Äá»“ng sá»­ dá»¥ng khi lÃ m PhÃ³ chá»§ nhiá»‡m cÆ¡ quan Biá»‡n sá»± xá»© táº¡i Quáº¿ LÃ¢m?', 'answers': {'text': ['LÃ¢m BÃ¡ Kiá»‡t'], 'answer_start': [507]}}\n"
          ]
        }
      ],
      "source": [
        "print(datasets[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRRRZqxTwbsk"
      },
      "source": [
        "## Preprocessing the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkPBqJGHwbsk"
      },
      "source": [
        "Before we can feed those texts to our model, we need to preprocess them. This is done by\n",
        "a ðŸ¤— Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs\n",
        "(including converting the tokens to their corresponding IDs in the pretrained vocabulary)\n",
        "and put it in a format the model expects, as well as generate the other inputs that model\n",
        "requires.\n",
        "\n",
        "To do all of this, we instantiate our tokenizer with the `XLMRobertaTokenizerFast.from_pretrained`\n",
        "method, which will ensure:\n",
        "\n",
        "- We get a tokenizer that corresponds to the model architecture we want to use.\n",
        "- We download the vocabulary used when pretraining this specific checkpoint.\n",
        "\n",
        "That vocabulary will be cached, so it's not downloaded again the next time we run the\n",
        "cell.\n",
        "\n",
        "The `from_pretrained()` method expects the name of a model. If you're unsure which model to\n",
        "pick, don't panic! The list of models to choose from can be bewildering, but in general\n",
        "there is a simple tradeoff: Larger models are slower and consume more memory, but usually\n",
        "yield slightly better final accuracies after fine-tuning. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WHSZXYU-wbsl"
      },
      "outputs": [],
      "source": [
        "from transformers import XLMRobertaTokenizerFast\n",
        "\n",
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E78uD_kjwbsl"
      },
      "source": [
        "\n",
        "\n",
        "If we simply truncate with a fixed size (`max_length`), we will lose information. We want to\n",
        "avoid truncating the question, and instead only truncate the context to ensure the task\n",
        "remains solvable. To do that, we'll set `truncation` to `\"only_second\"`, so that only the\n",
        "second sequence (the context) in each pair is truncated. To get the list of features\n",
        "capped by the maximum length, we need to set `return_overflowing_tokens` to True and pass\n",
        "the `doc_stride` to `stride`. To see which feature of the original context contain the\n",
        "answer, we can return `\"offset_mapping\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mpNDghN1wbsl"
      },
      "outputs": [],
      "source": [
        "max_length = 384  # The maximum length of a feature (question and context)\n",
        "doc_stride = (\n",
        "    128  # The authorized overlap between two part of the context when splitting\n",
        ")\n",
        "# it is needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sHTpR8mwbsm"
      },
      "source": [
        "In the case of impossible answers (the answer is in another feature given by an example\n",
        "with a long context), we set the cls index for both the start and end position. We could\n",
        "also simply discard those examples from the training set if the flag\n",
        "`allow_impossible_answers` is `False`. Since the preprocessing is already complex enough\n",
        "as it is, we've kept is simple for this part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q56_hiywwbsm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_train_features(examples):\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a\n",
        "    # stride. This results in one example possible giving several features when a context is long,\n",
        "    # each of those features having a context that overlaps a bit the context of the previous\n",
        "    # feature.\n",
        "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
        "    examples[\"context\"] = [c.lstrip() for c in examples[\"context\"]]\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a\n",
        "    # map from a feature to its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original\n",
        "    # context. This will help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what\n",
        "        # is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this\n",
        "        # span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != 1:\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the\n",
        "            # CLS index).\n",
        "            if not (\n",
        "                offsets[token_start_index][0] <= start_char\n",
        "                and offsets[token_end_index][1] >= end_char\n",
        "            ):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the\n",
        "                # answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge\n",
        "                # case).\n",
        "                while (\n",
        "                    token_start_index < len(offsets)\n",
        "                    and offsets[token_start_index][0] <= start_char\n",
        "                ):\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oNe69M1wbsm"
      },
      "source": [
        "To apply this function on all the sentences (or pairs of sentences) in our dataset, we\n",
        "just use the `map()` method of our `Dataset` object, which will apply the function on all\n",
        "the elements of.\n",
        "\n",
        "We'll use `batched=True` to encode the texts in batches together. This is to leverage the\n",
        "full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to\n",
        "treat the texts in a batch concurrently. We also use the `remove_columns` argument to\n",
        "remove the columns that existed before tokenization was applied - this ensures that the\n",
        "only features remaining are the ones we actually want to pass to our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z2NsU3dzwbsn",
        "outputId": "6ee8806c-e7a4-4007-bdcc-a499a370c66d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/trungds10___uit-vi-squad/squad_v2/2.0.0/5f19aa36ebeb9b5dc65031d4651dbedf62262d7034d4d2b9cca43a6694a23cb7/cache-cec0860382caee18.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/trungds10___uit-vi-squad/squad_v2/2.0.0/5f19aa36ebeb9b5dc65031d4651dbedf62262d7034d4d2b9cca43a6694a23cb7/cache-ef3be00feb1f0c85.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/trungds10___uit-vi-squad/squad_v2/2.0.0/5f19aa36ebeb9b5dc65031d4651dbedf62262d7034d4d2b9cca43a6694a23cb7/cache-36c5d150f5e67037.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/trungds10___uit-vi-squad/squad_v2/2.0.0/5f19aa36ebeb9b5dc65031d4651dbedf62262d7034d4d2b9cca43a6694a23cb7/cache-716b9a7a64b17c53.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/trungds10___uit-vi-squad/squad_v2/2.0.0/5f19aa36ebeb9b5dc65031d4651dbedf62262d7034d4d2b9cca43a6694a23cb7/cache-870b5ae00dbc7df7.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/trungds10___uit-vi-squad/squad_v2/2.0.0/5f19aa36ebeb9b5dc65031d4651dbedf62262d7034d4d2b9cca43a6694a23cb7/cache-72cd25772467b7e3.arrow\n"
          ]
        }
      ],
      "source": [
        "tokenized_datasets = datasets.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=datasets[\"train\"].column_names,\n",
        "    num_proc=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjmOoYCjwbsn"
      },
      "source": [
        "Even better, the results are automatically cached by the ðŸ¤— Datasets library to avoid\n",
        "spending time on this step the next time you run your notebook. The ðŸ¤— Datasets library is\n",
        "normally smart enough to detect when the function you pass to map has changed (and thus\n",
        "requires to not use the cache data). For instance, it will properly detect if you change\n",
        "the task in the first cell and rerun the notebook. ðŸ¤— Datasets warns you when it uses\n",
        "cached files, you can pass `load_from_cache_file=False` in the call to `map()` to not use\n",
        "the cached files and force the preprocessing to be applied again.\n",
        "\n",
        "Because all our data has been padded or truncated to the same length, and it is not too\n",
        "large, we can now simply convert it to a dict of numpy arrays, ready for training.\n",
        "\n",
        "Although we will not use it here, ðŸ¤— Datasets have a `to_tf_dataset()` helper method\n",
        "designed to assist you when the data cannot be easily converted to arrays, such as when\n",
        "it has variable sequence lengths, or is too large to fit in memory. This method wraps a\n",
        "`tf.data.Dataset` around the underlying ðŸ¤— Dataset, streaming samples from the underlying\n",
        "dataset and batching them on the fly, thus minimizing wasted memory and computation from\n",
        "unnecessary padding. If your use-case requires it, please see the\n",
        "[docs](https://huggingface.co/docs/transformers/custom_datasets#finetune-with-tensorflow)\n",
        "on to_tf_dataset and data collator for an example. If not, feel free to follow this example\n",
        "and simply convert to dicts!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "szCUVj_Ywbsn"
      },
      "outputs": [],
      "source": [
        "train_set = tokenized_datasets[\"train\"].with_format(\"numpy\")[\n",
        "    :\n",
        "]  # Load the whole dataset as a dict of numpy arrays\n",
        "validation_set = tokenized_datasets[\"validation\"].with_format(\"numpy\")[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD_1nkG3wbsn"
      },
      "source": [
        "## Fine-tuning the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqGeQYXQwbsn"
      },
      "source": [
        "That was a lot of work! But now that our data is ready, everything is going to run very\n",
        "smoothly. First, we download the pretrained model and fine-tune it. Since our task is\n",
        "question answering, we use the `TFAutoModelForQuestionAnswering` class. Like with the\n",
        "tokenizer, the `from_pretrained()` method will download and cache the model for us:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, AutoModelForQuestionAnswering\n",
        "\n",
        "# see https://huggingface.co/docs/transformers/main_classes/configuration\n",
        "config = AutoConfig.from_pretrained(\n",
        "    \"xlm-roberta-base\",\n",
        "    num_labels=2,\n",
        "    hidden_size=768,\n",
        ")\n",
        "model = (AutoModelForQuestionAnswering\n",
        "         .from_pretrained(\"xlm-roberta-base\", config=config)\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "df11e16e7d004a878464fdd3895a042d",
            "3888d537d70549e9a31b15fe35337ab7",
            "0f620e3a19744fb39f6ce735a423bfbd",
            "d38065931004457382130dc04b9770b9",
            "2fca1e9207b14b8a9ccd133fa14a8580",
            "6d03c4c6641c4fe9baa122163496c195",
            "213dc59e60b0415fa4c9a60a411331dd",
            "30a7231d5bd849aa8fac959577e7e815",
            "d73d4df5a1244b899c5d16b7b308bcfc",
            "f9fe370c83a04743984e90cb47889376",
            "81c7c71f998f4c04b3b249a56aab9ebf",
            "bda8d323813d48cc868a97803c1d3652",
            "839f34fa2dbb4e24907f1a73caa392cc",
            "0ef3e7f64cf3439996bdaf555499e6fb",
            "884137f8ed4d46c386aebd6654d878b8",
            "ddbff8ea52b5417e8c3797f474a6a260",
            "4db925c690fc43c393504580ea298e1c",
            "8b448dda7d9946b9aa12700f1dcef7a3",
            "0d578b7108554ffd816dd20c5ba19e28",
            "ada0770da70948798f754706798df904",
            "7fb3e26a28ae44ddb36ac1887dcb16b4",
            "9539ba0811364654937d7eb8b45d299a"
          ]
        },
        "id": "cCn3efEfckfj",
        "outputId": "494907de-050e-441f-91d1-d3cf681e1058"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df11e16e7d004a878464fdd3895a042d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bda8d323813d48cc868a97803c1d3652"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ],
      "metadata": {
        "id": "Db6IjtYId5V7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw7HTUVawbso"
      },
      "source": [
        "The warning is telling us we are throwing away some weights and newly initializing some\n",
        "others. Don't panic! This is absolutely normal. Recall that models like BERT and\n",
        "Distilbert are trained on a **language modeling** task, but we're loading the model as\n",
        "a `TFAutoModelForQuestionAnswering`, which means we want the model to perform a\n",
        "**question answering** task. This change requires the final output layer or \"head\" to be\n",
        "removed and replaced with a new head suited for the new task. The `from_pretrained`\n",
        "method will handle all of this for us, and the warning is there simply to remind us that\n",
        "some model surgery has been performed, and that the model will not generate useful\n",
        "predictions until the newly-initialized layers have been fine-tuned on some data.\n",
        "\n",
        "Next, we can create an optimizer and specify a loss function. You can usually get\n",
        "slightly better performance by using learning rate decay and decoupled weight decay, but\n",
        "for the purposes of this example the standard `Adam` optimizer will work fine. Note,\n",
        "however, that when fine-tuning a pretrained transformer model you will generally want to\n",
        "use a low learning rate! We find the best results are obtained with values in the range\n",
        "1e-5 to 1e-4, and training may completely diverge at the default Adam learning rate of 1e-3."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"trungds\",\n",
        "    log_level = \"error\",\n",
        "    num_train_epochs = 3,\n",
        "    learning_rate = 7e-5,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    warmup_steps = 100,\n",
        "    per_device_train_batch_size = 2,\n",
        "    per_device_eval_batch_size = 1,\n",
        "    gradient_accumulation_steps = 16,\n",
        "    evaluation_strategy = \"steps\",\n",
        "    eval_steps = 150,\n",
        "    save_steps = 500,\n",
        "    logging_steps = 50,\n",
        "    push_to_hub = False\n",
        ")"
      ],
      "metadata": {
        "id": "1ZHmSHv_d57w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator = data_collator,\n",
        "    train_dataset = tokenized_datasets[\"train\"],\n",
        "    eval_dataset = tokenized_datasets[\"validation\"].select(range(100)),\n",
        "    tokenizer = tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "sSOk4uEEeBl6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RhFoqU5wbso"
      },
      "source": [
        "And now we just compile and fit the model. As a convenience, all ðŸ¤— Transformers models\n",
        "come with a default loss which matches their output head, although you're of course free\n",
        "to use your own. Because the built-in loss is computed internally during the forward\n",
        "pass, when using it you may find that some Keras metrics misbehave or give unexpected\n",
        "outputs. This is an area of very active development in ðŸ¤— Transformers, though, so\n",
        "hopefully we'll have a good solution to that issue soon!\n",
        "\n",
        "For now, though, let's use the built-in loss without any metrics. To get the built-in\n",
        "loss, simply leave out the `loss` argument to `compile`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "oXRAlkDceJ7R",
        "outputId": "3bafcc88-ba4b-4cd2-d8fd-75d2a4142179"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2850' max='2850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2850/2850 2:03:58, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.572500</td>\n",
              "      <td>2.597296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.917400</td>\n",
              "      <td>1.995494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.851100</td>\n",
              "      <td>2.023351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.763600</td>\n",
              "      <td>1.898478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.658400</td>\n",
              "      <td>1.825791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.620800</td>\n",
              "      <td>1.847045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>1.298500</td>\n",
              "      <td>1.776040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.283400</td>\n",
              "      <td>1.757387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>1.277500</td>\n",
              "      <td>1.651042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.260900</td>\n",
              "      <td>1.605081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>1.236700</td>\n",
              "      <td>1.599021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.286000</td>\n",
              "      <td>1.663619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>1.835637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.957400</td>\n",
              "      <td>1.773242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.984700</td>\n",
              "      <td>1.909457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.926900</td>\n",
              "      <td>1.765533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.930500</td>\n",
              "      <td>1.840645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.912200</td>\n",
              "      <td>1.833036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.891000</td>\n",
              "      <td>1.817137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2850, training_loss=1.4242638651529949, metrics={'train_runtime': 7442.1333, 'train_samples_per_second': 12.255, 'train_steps_per_second': 0.383, 'total_flos': 1.7873482051012608e+16, 'train_loss': 1.4242638651529949, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"./xlm-vie-trung\", exist_ok=True)\n",
        "if hasattr(trainer.model, \"module\"):\n",
        "    trainer.model.module.save_pretrained(\"./xlm-vie-trung\")\n",
        "else:\n",
        "    trainer.model.save_pretrained(\"./xlm-vie-trung\")"
      ],
      "metadata": {
        "id": "lKzxULjVe9YM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering\n",
        "\n",
        "model = (AutoModelForQuestionAnswering\n",
        "         .from_pretrained(\"./xlm-vie-trung\")\n",
        "         )"
      ],
      "metadata": {
        "id": "BN9yol4ge_8B"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0)\n",
        "\n",
        "idx = 0\n",
        "print(\"***** context *****\")\n",
        "print(datasets[\"validation\"][\"context\"][idx])\n",
        "print(\"\")\n",
        "print(\"***** question *****\")\n",
        "print(datasets[\"validation\"][\"question\"][idx])\n",
        "print(\"\")\n",
        "print(\"***** true answer *****\")\n",
        "print(datasets[\"validation\"][\"answers\"][idx][\"text\"][0])\n",
        "print(\"\")\n",
        "print(\"***** predicted top3 answer *****\")\n",
        "qa_pipeline(\n",
        "    question = datasets[\"validation\"][\"question\"][idx],\n",
        "    context = datasets[\"validation\"][\"context\"][idx],\n",
        "    align_to_words = False,\n",
        "    top_k=3,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYEnE3OpfDOj",
        "outputId": "01944965-497c-4345-db79-73ccc94097aa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** context *****\n",
            "Paris náº±m á»Ÿ Ä‘iá»ƒm gáº·p nhau cá»§a cÃ¡c hÃ nh trÃ¬nh thÆ°Æ¡ng máº¡i Ä‘Æ°á»ng bá»™ vÃ  Ä‘Æ°á»ng sÃ´ng, vÃ  lÃ  trung tÃ¢m cá»§a má»™t vÃ¹ng nÃ´ng nghiá»‡p giÃ u cÃ³. VÃ o tháº¿ ká»· 10, Paris Ä‘Ã£ lÃ  má»™t trong nhá»¯ng thÃ nh phá»‘ chÃ­nh cá»§a PhÃ¡p cÃ¹ng cÃ¡c cung Ä‘iá»‡n hoÃ ng gia, cÃ¡c tu viá»‡n vÃ  nhÃ  thá». Tá»« tháº¿ ká»· 12, Paris trá»Ÿ thÃ nh má»™t trong nhá»¯ng trung tÃ¢m cá»§a chÃ¢u Ã‚u vá» giÃ¡o dá»¥c vÃ  nghá»‡ thuáº­t. Tháº¿ ká»· 14, Paris lÃ  thÃ nh phá»‘ quan trá»ng báº­c nháº¥t cá»§a CÆ¡ Äá»‘c giÃ¡o vÃ  trong cÃ¡c tháº¿ ká»· 16, 17, Ä‘Ã¢y lÃ  nÆ¡i diá»…n ra CÃ¡ch máº¡ng PhÃ¡p cÃ¹ng nhiá»u sá»± kiá»‡n lá»‹ch sá»­ quan trá»ng cá»§a PhÃ¡p vÃ  chÃ¢u Ã‚u. Äáº¿n tháº¿ ká»· 19 vÃ  20, thÃ nh phá»‘ trá»Ÿ thÃ nh má»™t trong nhá»¯ng trung tÃ¢m vÄƒn hÃ³a cá»§a tháº¿ giá»›i, thá»§ Ä‘Ã´ cá»§a nghá»‡ thuáº­t vÃ  giáº£i trÃ­.\n",
            "\n",
            "***** question *****\n",
            "Paris Ä‘áº¡t Ä‘Æ°á»£c thÃ nh quáº£ gÃ¬ sau khoáº£ng 4 tháº¿ ká»· tÃ­nh tá»« ngÃ y CÃ¡ch máº¡ng PhÃ¡p diá»…n ra?\n",
            "\n",
            "***** true answer *****\n",
            "trá»Ÿ thÃ nh má»™t trong nhá»¯ng trung tÃ¢m vÄƒn hÃ³a cá»§a tháº¿ giá»›i, thá»§ Ä‘Ã´ cá»§a nghá»‡ thuáº­t vÃ  giáº£i trÃ­\n",
            "\n",
            "***** predicted top3 answer *****\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.001704279100522399,\n",
              "  'start': 555,\n",
              "  'end': 621,\n",
              "  'answer': 'thÃ nh phá»‘ trá»Ÿ thÃ nh má»™t trong nhá»¯ng trung tÃ¢m vÄƒn hÃ³a cá»§a tháº¿ giá»›i'},\n",
              " {'score': 0.0008764154626987875,\n",
              "  'start': 623,\n",
              "  'end': 656,\n",
              "  'answer': 'thá»§ Ä‘Ã´ cá»§a nghá»‡ thuáº­t vÃ  giáº£i trÃ­'},\n",
              " {'score': 0.00015209632692858577,\n",
              "  'start': 565,\n",
              "  'end': 621,\n",
              "  'answer': 'trá»Ÿ thÃ nh má»™t trong nhá»¯ng trung tÃ¢m vÄƒn hÃ³a cá»§a tháº¿ giá»›i'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac94f895defc48a589dca8bf03f12b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0ea51a113b146c390edc2127ee15b16",
              "IPY_MODEL_25fe697708cf45fdbfcd54c0a987beeb",
              "IPY_MODEL_ed0c24e76ab546119559eea0545914b6"
            ],
            "layout": "IPY_MODEL_bb27c1d8b4754fc5b9bb8cd54499f87b"
          }
        },
        "b0ea51a113b146c390edc2127ee15b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa4e7b2bdd3436fb67cdc8be5f4c61c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a89354e3aca0448389bbafba72b7c96e",
            "value": "100%"
          }
        },
        "25fe697708cf45fdbfcd54c0a987beeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf4d906d4504139b1d151838ae711d9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80928868adcb4686a73930be5af4151a",
            "value": 2
          }
        },
        "ed0c24e76ab546119559eea0545914b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36d53e5d6f9f44d8aff410eb5ecc57f0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bdc47afcbc3045b784e74631b1d1f298",
            "value": " 2/2 [00:00&lt;00:00, 97.44it/s]"
          }
        },
        "bb27c1d8b4754fc5b9bb8cd54499f87b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aa4e7b2bdd3436fb67cdc8be5f4c61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89354e3aca0448389bbafba72b7c96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bf4d906d4504139b1d151838ae711d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80928868adcb4686a73930be5af4151a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36d53e5d6f9f44d8aff410eb5ecc57f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc47afcbc3045b784e74631b1d1f298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df11e16e7d004a878464fdd3895a042d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3888d537d70549e9a31b15fe35337ab7",
              "IPY_MODEL_0f620e3a19744fb39f6ce735a423bfbd",
              "IPY_MODEL_d38065931004457382130dc04b9770b9"
            ],
            "layout": "IPY_MODEL_2fca1e9207b14b8a9ccd133fa14a8580"
          }
        },
        "3888d537d70549e9a31b15fe35337ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d03c4c6641c4fe9baa122163496c195",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_213dc59e60b0415fa4c9a60a411331dd",
            "value": "Downloading: 100%"
          }
        },
        "0f620e3a19744fb39f6ce735a423bfbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30a7231d5bd849aa8fac959577e7e815",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d73d4df5a1244b899c5d16b7b308bcfc",
            "value": 615
          }
        },
        "d38065931004457382130dc04b9770b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9fe370c83a04743984e90cb47889376",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_81c7c71f998f4c04b3b249a56aab9ebf",
            "value": " 615/615 [00:00&lt;00:00, 35.8kB/s]"
          }
        },
        "2fca1e9207b14b8a9ccd133fa14a8580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d03c4c6641c4fe9baa122163496c195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213dc59e60b0415fa4c9a60a411331dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30a7231d5bd849aa8fac959577e7e815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73d4df5a1244b899c5d16b7b308bcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9fe370c83a04743984e90cb47889376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81c7c71f998f4c04b3b249a56aab9ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bda8d323813d48cc868a97803c1d3652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_839f34fa2dbb4e24907f1a73caa392cc",
              "IPY_MODEL_0ef3e7f64cf3439996bdaf555499e6fb",
              "IPY_MODEL_884137f8ed4d46c386aebd6654d878b8"
            ],
            "layout": "IPY_MODEL_ddbff8ea52b5417e8c3797f474a6a260"
          }
        },
        "839f34fa2dbb4e24907f1a73caa392cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db925c690fc43c393504580ea298e1c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8b448dda7d9946b9aa12700f1dcef7a3",
            "value": "Downloading: 100%"
          }
        },
        "0ef3e7f64cf3439996bdaf555499e6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d578b7108554ffd816dd20c5ba19e28",
            "max": 1115590446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ada0770da70948798f754706798df904",
            "value": 1115590446
          }
        },
        "884137f8ed4d46c386aebd6654d878b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fb3e26a28ae44ddb36ac1887dcb16b4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9539ba0811364654937d7eb8b45d299a",
            "value": " 1.12G/1.12G [00:19&lt;00:00, 83.8MB/s]"
          }
        },
        "ddbff8ea52b5417e8c3797f474a6a260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db925c690fc43c393504580ea298e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b448dda7d9946b9aa12700f1dcef7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d578b7108554ffd816dd20c5ba19e28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ada0770da70948798f754706798df904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fb3e26a28ae44ddb36ac1887dcb16b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9539ba0811364654937d7eb8b45d299a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}